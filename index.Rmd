---
title: "Phishing with SQL"
description: |
  Welcome to the website. I hope you enjoy it!
site: distill::distill_website
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(tidyverse)
library(dplyr)
library(rmarkdown)
library(plotly)
library(ggplot2)
library(distill)

```


We started with [fake news](https://zhusophia.github.io/Fake_Fake_News/), only to end up at phishing. That's just how the world works! 

Taking raw data from [this dataset](https://www.kaggle.com/datasets/danielfernandon/web-page-phishing-dataset?resource=download), I'm attempting to explore the URLs of phishing websites! 

Taking a look at the raw data: 

DISPLAY RAW DATA 
- grab a first 4 columns + phishing column (move phsidhing column tot he front)


```{r load data}
data <- read.csv("web-page-phishing.csv")
```

```{r general data}


data <- data %>% 
  select(phishing, everything())

paged_table(head(data))

```
<!-- ggplot(phishingpie, aes(x="", y=occurances, fill=phishing)) +
  geom_col() +
  coord_polar(theta="y")+
  theme_void()


-->

```{r phishing pie chart}

phishingpie <- data %>%
  select(phishing) %>%
  group_by(phishing) %>% 
  summarise(occurances = n()) %>%
  mutate(phishing = recode(phishing, '1'='Phishing link', '0'="Non-phishing link"))

phishingagg <- plot_ly(phishingpie, labels = ~phishing, values = ~occurances, type = 'pie',marker = list(colors = c('#CC6666', '#9999CC')),
        textposition = 'inside',
        textinfo = 'label+percent',
        insidetextfont = list(color = '#FFFFFF'),
        hoverinfo = 'text',
        text = ~paste(occurances, 'links')) %>% 
  layout(title="Phishing V.S. Non-Phishing Links", 
         legend = list(x = 100, y = 0.5, title=list(text='<b> Types of Websites </b>')))

phishingagg

```


We've got a smattering of data! Now, I want to analyze the data further: What is the correlation between phishing and each column? Employing the use of SQL: 

I'm going to be calcualting Pearson's correlation. It is 


explain topics: 
- standard deviation -> measure of how dispersed the data is in relation to the mean
- varianece -> 
- correlation
- hypothesis testing? 


```{sql test, eval=FALSE, echo=T} 
can you display just this as something
```


<!--




ggplot(urldata, aes(x=url_length, color=phishing)) + 
  geom_density()
---> 
```{r url_length m_and_sd}

pmean <- data %>% 
  select( phishing, url_length) %>%
  filter(phishing==1) %>%
  summarise(mean_p = mean(url_length))

psd <- data %>% 
  select( phishing, url_length) %>%
  filter(phishing==1) %>%
  summarise(sd_p = sd(url_length))

npmean <- data %>% 
  select( phishing, url_length) %>%
  filter(phishing==0) %>%
  summarise(mean_np = mean(url_length))

npsd <- data %>% 
  select( phishing, url_length) %>%
  filter(phishing==0) %>%
  summarise(sd_np = sd(url_length))

data.frame(pmean, psd, npmean, npsd)


```
```{r urldensity}

urldensity <- data.frame(
  phishingurl=factor(rep(c("Phishing", "Not Phishing"), each=300)),
  weight=round(c(rnorm(300, mean=66.49112, sd=68.59874),
                 rnorm(300, mean=23.58997	, sd=16.13607)))
  )


p <- ggplot(urldensity, aes(x=weight, color=phishingurl)) +
  geom_density() +
  geom_vline(aes(xintercept=66.49112),
             linetype="dashed", color='blue') +
  geom_vline(aes(xintercept=23.58997),
             linetype="dashed", color='blue') 
  p + scale_x_continuous(expand = c(0, 0), limits = c(0, NA)) + 
  scale_y_continuous(expand = c(0, 0), limits = c(0, NA), labels = scales::percent) +
    scale_color_manual(values=c("#CC6666", "#9999CC")) +
    labs(title = "URL Character Distribution", 
         subtitle = "Phishing URLs typically have more characters\n", 
         x = "\n Number of characters", 
         y = "Density \n", 
         color = "Types of URLs")

```
- make the links open to a blank page 


i can make a density plot for n_slash, n_urllength, n_redirections 
--> Histogram, Box plots, scatterplot
- t test 
- linear regression
- think i can also use the average measure to rpove 
- conduct hypothesis testing on all three? 
- descriptive statistics 
- r^2 and r? regresison analysis 

https://www.youtube.com/watch?v=VK-rnA3-41c

- general talk about teh data 
-> how many were fishing? how many weren't? -> pie chart 

correlation 
- build tables (take the head of x)
- explain the pearson correlation, how can we get info out 
- cast bigint and basically couldn twork, so had to build a table (you can build it using R)
create table 


url length 
- out of phishing, plot density graph, 
--> url lenght vs amount of urls -> phishing vs no phishing 

same thing with redirections 

- end

this shoudl be pretty quick and simple it hink

https://docs.google.com/spreadsheets/d/1JNzGqUo9HEn5WOKftEgcm94JddOK6G3_QW-UI4sFNUY/edit#gid=0

https://docs.google.com/document/d/1M9kvGEJ1_db81M5g6J8DtF0kAFnCCAPlnuUMzAmVUOA/edit
